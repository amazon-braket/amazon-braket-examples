{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021cfd04-df68-414d-a864-48f62fc8ddfb",
   "metadata": {},
   "source": [
    "# Parallel simulations on multiple GPUs\n",
    "\n",
    "Many quantum algorithms require running a batch of circuits and observables. For example, evaluating a Hamiltonian requires evaluating many terms of the Hamiltonian. \n",
    "\n",
    "In this notebook, you will learn how to use parallelization to tackle these challenges. With CUDA-Q and Braket Hybrid Jobs, the simulation of a batch of observables and circuits can be parallelized over multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b46659-6dcc-4900-a13a-e971f8bf0590",
   "metadata": {},
   "source": [
    "We start with necessary imports that are used in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8738f65f-969c-4b58-96f8-69bbc1bad5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from braket.jobs import hybrid_job\n",
    "from braket.jobs.config import InstanceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331136a-a369-4eef-8bfe-252c79103a3e",
   "metadata": {},
   "source": [
    "Next, specify the URI of the container image that supports CUDA-Q. If you went through the \"0_hello_cudaq_jobs.ipynb\" notebook, you can use the same image URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25fdc720-3143-411a-8bef-f9623369b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = \"<image-uri>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d60f04-e412-4d7c-9fdc-9f421e8c8ae1",
   "metadata": {},
   "source": [
    "## Simulation on a single GPU\n",
    "\n",
    "We start by running a job on a single GPU. This example job evaluates a circuit with terms in the Hamiltonian. The ml.p3.2xlarge instance type used in the example has one GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64e5d4e1-df6d-4a8f-af4f-89fec9e77791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping python version validation, make sure versions match between local environment and container.\n"
     ]
    }
   ],
   "source": [
    "@hybrid_job(\n",
    "    device=\"local:nvidia/nvidia\",\n",
    "    instance_config=InstanceConfig(instanceType=\"ml.p3.2xlarge\"),\n",
    "    image_uri=image_uri,\n",
    ")\n",
    "def single_gpu_job(n_qubits, n_terms, n_shots):\n",
    "    import cudaq\n",
    "\n",
    "    # Define backend\n",
    "    cudaq.set_target(\"nvidia\")\n",
    "    print(\"CUDA-Q backend: \", cudaq.get_target())\n",
    "\n",
    "    # Define circuit and observables\n",
    "    kernel = cudaq.make_kernel()\n",
    "    qubits = kernel.qalloc(n_qubits)\n",
    "    kernel.h(qubits[0])\n",
    "    for i in range(1, n_qubits):\n",
    "        kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "    hamiltonian = cudaq.SpinOperator.random(n_qubits, n_terms, seed=2024)\n",
    "\n",
    "    # Run circuit simulation\n",
    "    t0 = time.time()\n",
    "    result = cudaq.observe(kernel, hamiltonian, shots_count=n_shots)\n",
    "    t1 = time.time()\n",
    "    total_time = t1 - t0\n",
    "    print(f\"result: {result.expectation()} | time: {total_time}\")\n",
    "\n",
    "    return {\"expectation\": result.expectation(), \"total_time\": total_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3d03c-18cb-4907-8acf-3a4a04d4b859",
   "metadata": {},
   "source": [
    "The evaluation of the Hamiltonian terms are done on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8af4b8-ac8f-4d7e-959c-a82ed2559824",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 20\n",
    "n_terms = 4000\n",
    "n_shots = 1000\n",
    "\n",
    "single_job = single_gpu_job(n_qubits, n_terms, n_shots)\n",
    "print(\"Job ARN: \", single_job.arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = single_job.result()\n",
    "print(f\"result: {result['expectation']} | time: {result['total_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083df36f-8ec4-468d-8e68-36c1fc1f4f5c",
   "metadata": {},
   "source": [
    "## Parallelize the simulation of a batch of observables\n",
    "\n",
    "Let's tackle the same problem again. But this time, we will run the simulation on multiple GPUs across multiple nodes using the [MPI interface](https://nvidia.github.io/cuda-quantum/latest/using/install/data_center_install.html#mpi). To do so, you add the keyword argument `execution=cudaq.parallel.mpi` to the `cudaq.observe()` call. With this keyword argument, CUDA-Q will distribute the simulation over the GPUs available in a job.\n",
    "\n",
    "In order for CUDA-Q to distribute the simulation, there are some prerequisites. First, the job needs to run on instances that have many GPUs. To achieve this, you can specify the instance type that has multiple GPUs (e.g., ml.p3.8xlarge). If the number of GPUs on a single instance is not enough, you can extend the parallelization to multiple nodes by specifying `instanceCount` being larger than 1. Then, you need to add a hyperparameter `sagemaker_mpi_enabled=True` to the job which will initialize the job environment to support parallelization with MPI. Next, you need to select a CUDA-Q backend that supports distribution (e.g., `nvidia` backend with the `mqpu` option). Finally, you need to initialize the MPI interface in your CUDA-Q code. The code snippet below provides example of all these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "089e29a4-f83a-43bb-ad8e-04dcfc086d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping python version validation, make sure versions match between local environment and container.\n"
     ]
    }
   ],
   "source": [
    "@hybrid_job(\n",
    "    device=\"local:nvidia/nvidia-mqpu\",\n",
    "    instance_config=InstanceConfig(instanceType=\"ml.p3.8xlarge\", instanceCount=1),\n",
    "    image_uri=image_uri,\n",
    ")\n",
    "def parallel_observables_gpu_job(\n",
    "    n_qubits,\n",
    "    n_terms,\n",
    "    n_shots,\n",
    "    sagemaker_mpi_enabled=True,\n",
    "):\n",
    "    import cudaq\n",
    "\n",
    "    # Define target\n",
    "    cudaq.set_target(\"nvidia\", option=\"mqpu\")\n",
    "    print(\"CUDA-Q backend: \", cudaq.get_target())\n",
    "    print(\"num_available_gpus: \", cudaq.num_available_gpus())\n",
    "    cudaq.set_random_seed(2024)\n",
    "\n",
    "    # Initialize MPI and view the MPI properties\n",
    "    cudaq.mpi.initialize()\n",
    "    num_ranks = cudaq.mpi.num_ranks()\n",
    "    rank = cudaq.mpi.rank()\n",
    "    print(f\"rank={rank} | MPI is initialized? {cudaq.mpi.is_initialized()}\")\n",
    "    print(f\"rank={rank}, num_ranks={num_ranks}\")\n",
    "\n",
    "    # Define circuit and observables\n",
    "    kernel = cudaq.make_kernel()\n",
    "    qubits = kernel.qalloc(n_qubits)\n",
    "    kernel.h(qubits[0])\n",
    "    for i in range(1, n_qubits):\n",
    "        kernel.cx(qubits[0], qubits[i])\n",
    "\n",
    "    hamiltonian = cudaq.SpinOperator.random(n_qubits, n_terms, seed=2024)\n",
    "\n",
    "    # Parallelize circuit simulation\n",
    "    t0 = time.time()\n",
    "    result = cudaq.observe(\n",
    "        kernel, hamiltonian, shots_count=n_shots, execution=cudaq.parallel.mpi\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    total_time = t1 - t0\n",
    "    print(f\"rank={rank} | result: {result.expectation()} | time: {total_time}\")\n",
    "\n",
    "    # End the MPI interface\n",
    "    cudaq.mpi.finalize()\n",
    "\n",
    "    if rank == 0:\n",
    "        return {\"expectation\": result.expectation(), \"total_time\": total_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7039a-9d3c-46cb-ab62-22d7f0951b13",
   "metadata": {},
   "source": [
    "When the `parallel_job` function is called, it creates a job that distributes the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f6673-35ba-4657-9f4a-f263d8b687db",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_obs_job = parallel_observables_gpu_job(n_qubits=27, n_terms=2000, n_shots=1000)\n",
    "print(\"Job ARN: \", parallel_obs_job.arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_obs_result = parallel_obs_job.result()\n",
    "print(\n",
    "    f\"result: {parallel_obs_result['expectation']} | time: {parallel_obs_result['total_time']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644c167-1b1b-4905-a697-b2b829ecc2c2",
   "metadata": {},
   "source": [
    "## Parallelize the simulation of a batch of circuits\n",
    "In this section, we show an example of parallelizing the simulation of a circuit batch over multiple GPUs. First, we import a function `parametric_random_circuit_generator_factory` from \"random_circuits.py\" to use a circuit generator of random parametric circuits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f0deeb1-0b29-42ef-b4d6-de428af65d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_circuits import parametric_random_circuit_generator_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab1628-4622-4e24-8cdd-f4a686b05e5a",
   "metadata": {},
   "source": [
    "In this example, the circuit batch is formed by a single parametric circuit with many different sets of parameters. To assign a parameter set to a particular GPU, you can use the `qpu_id` keyword in the `cudaq.observe_async()` call. For example, to assign a simulation to GPU with rank 5, you set `qpu_id=5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c347a967-d364-481b-b0a8-a9e9fd21467f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping python version validation, make sure versions match between local environment and container.\n"
     ]
    }
   ],
   "source": [
    "@hybrid_job(\n",
    "    device=\"local:nvidia/nvidia-mqpu\",\n",
    "    instance_config=InstanceConfig(instanceType=\"ml.p3.8xlarge\"),\n",
    "    include_modules=\"random_circuits\",\n",
    "    image_uri=image_uri,\n",
    ")\n",
    "def parallel_batch_gpu_job(\n",
    "    n_qubits, n_terms, n_shots, n_gates=100, n_circuits=128, sagemaker_mpi_enabled=True\n",
    "):\n",
    "    import cudaq\n",
    "\n",
    "    # Define target\n",
    "    cudaq.set_target(\"nvidia\", option=\"mqpu\")\n",
    "    print(\"CUDA-Q backend: \", cudaq.get_target())\n",
    "\n",
    "    # Initialize MPI and view the MPI properties\n",
    "    cudaq.mpi.initialize()\n",
    "    num_ranks = cudaq.mpi.num_ranks()\n",
    "    rank = cudaq.mpi.rank()\n",
    "    print(f\"rank={rank} | MPI is initialized? {cudaq.mpi.is_initialized()}\")\n",
    "    print(f\"rank={rank}, num_ranks={num_ranks}\")\n",
    "\n",
    "    # Define parametric circuit and observables\n",
    "    hamiltonian = cudaq.SpinOperator.random(n_qubits, n_terms)\n",
    "    get_parametric_random_circuit = parametric_random_circuit_generator_factory()\n",
    "    parametric_circuit, n_params = get_parametric_random_circuit(n_qubits, n_gates)\n",
    "\n",
    "    # Run parallel execution\n",
    "    num_gpus = int(num_ranks)\n",
    "    asyncresults = []\n",
    "    for i in range(n_circuits):\n",
    "        qpu_id = i % num_gpus\n",
    "        params = np.random.uniform(0, np.pi, size=n_params)\n",
    "        asyncresults.append(\n",
    "            cudaq.observe_async(\n",
    "                parametric_circuit,\n",
    "                hamiltonian,\n",
    "                params,\n",
    "                shots_count=n_shots,\n",
    "                qpu_id=qpu_id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "    _ = [res.get() for res in asyncresults]\n",
    "    t1 = time.time()\n",
    "\n",
    "    # End the MPI interface\n",
    "    cudaq.mpi.finalize()\n",
    "\n",
    "    if rank == 0:\n",
    "        return t1 - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ed99f-43be-40ac-b711-bcb53d3fe61f",
   "metadata": {},
   "source": [
    "When the `parallel_multi_gpu_job` function is called, it creates a job that distributes the simulation of the circuit batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167a067-7ab0-47c9-8b3f-b2394ee0335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 15\n",
    "n_gates = 100\n",
    "n_terms = 20\n",
    "n_shots = 500\n",
    "n_circuits = 128\n",
    "\n",
    "parallel_batch_job = parallel_batch_gpu_job(\n",
    "    n_qubits,\n",
    "    n_terms,\n",
    "    n_shots,\n",
    "    n_gates,\n",
    "    n_circuits,\n",
    ")\n",
    "print(\"Job ARN: \", parallel_batch_job.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30ffdb-dbc5-4000-af8e-c63dd713d153",
   "metadata": {},
   "source": [
    "Currently, `observe_async()` only supports distribution over GPUs on the same node, so the `qpu_id` needs to be consistent with the number of GPUs of a single instance used in the job. However, if you wish to distribute the circuit batch over multiple nodes, you can manually assign different circuit batches to different nodes with the following MPI logic:\n",
    "```\n",
    "ngpu_per_node = ... # number of gpus per node\n",
    "circuit_batch_0 = ... # circuit batch for node 0\n",
    "circuit_batch_1 = ... # circuit batch for node 1\n",
    "\n",
    "if cudaq.mpi.rank()//ngpu_per_node==0:\n",
    "    for circuit in circuit_batch_0:\n",
    "        cudaq.observe_async(circuit, hamiltonian, shots_count=n_shots, qpu_id=qpu_id)\n",
    "if cudaq.mpi.rank()//ngpu_per_node==1:\n",
    "    for circuit in circuit_batch_1:\n",
    "        cudaq.observe_async(circuit, hamiltonian, shots_count=n_shots, qpu_id=qpu_id)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18004fe8-24a0-4316-ab0a-a4e0aac6ba1e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook shows you how to parallelize the simulation of a state vector and the simulation of multiple circuits across GPUs. If you have workloads with a large qubit count or a large number of circuits to evaluate, you can use parallelization to speedup the simulation of your workloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
