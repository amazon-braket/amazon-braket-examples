{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab11422e",
   "metadata": {},
   "source": [
    "# QAOA with Amazon Braket Hybrid Jobs and PennyLane\n",
    "\n",
    "In this tutorial, we use PennyLane within Amazon Braket Hybrid Jobs to run the Quantum Approximate Optimization Algorithm (QAOA) on a Max-Cut problem.\n",
    "\n",
    "## Learning outcomes\n",
    "* Use pre-built PennyLane containers in Braket Jobs\n",
    "* Set QAOA hyperparameters \n",
    "* Choose PennyLane backend (TensorFlow, PyTorch, Base)\n",
    "* Use checkpoints for Braket Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69383d24",
   "metadata": {},
   "source": [
    "## QAOA background \n",
    "\n",
    "QAOA is a variational algorithm that uses parameterized quantum circuits to evaluate a classical cost function given by a binary optimization problem; the circuit parameters are iteratively adjusted to minimize the cost function. The QAOA algorithm itself has different settings, such as circuit depth ($p$). In analogy to machine learning, these input settings are commonly referred to as _hyperparameters_. In the following, we show how to setup the problem, prepare input data and run QAOA using Braket Jobs.\n",
    "\n",
    "For more information about QAOA and PennyLane, see [this example notebook](../../pennylane/2_Graph_optimization_with_QAOA/2_Graph_optimization_with_QAOA.ipynb) or [this PennyLane tutorial](https://pennylane.ai/qml/demos/tutorial_qaoa_intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c0595",
   "metadata": {},
   "source": [
    "## Problem setup\n",
    "\n",
    "A Max Cut problem is the problem to find a cut in a graph that maximizes the number of edges between the two parts after the cut. It has applications in theoretical physics and in combinatorial optimizations. To get started, we first create and visualize a random graph for the Max-Cut problem with <code>networkx</code> package. Feel free to adjust the number of nodes, <code>n</code>, and number of edges, <code>m</code> as part of your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde521bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a random graph with num_nodes nodes and num_edges edges to run Max Cut on.\n",
    "# num_nodes is the number of nodes in your graph, each represented by one qubit.\n",
    "# Caution: Circuit runtimes will scale exponentially with num_nodes\n",
    "\n",
    "num_nodes = 21\n",
    "num_edges = 42\n",
    "seed = 1967\n",
    "\n",
    "p = 2\n",
    "\n",
    "graph = nx.gnm_random_graph(num_nodes, num_edges, seed=seed)\n",
    "\n",
    "# Draw the graph\n",
    "positions = nx.spring_layout(graph, seed=seed)\n",
    "nx.draw(graph, with_labels=True, pos=positions, node_size=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNCOMMENT_TO_RUN\n",
    "# num_nodes = 6\n",
    "# num_edges = 8\n",
    "# seed = 1967"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c608e",
   "metadata": {},
   "source": [
    "## Prepare input data\n",
    "We will prepare the optimization problem we want to solve, represented by the so-called Ising matrix, as the input data for the Braket Job. This best practice helps us decouple our problem definition from our algorithm code. If we want to solve another instance of this problem type, all we need to do is to point a new job to the new input data. The input data can be specified by either a path to a local file, or an Amazon S3 path that points to the data. For this example, we will create a file in the local directory encoding the problem graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"input-data.adjlist\"\n",
    "\n",
    "nx.write_adjlist(graph, input_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e9b83",
   "metadata": {},
   "source": [
    "## Define the circuit\n",
    "\n",
    "The ansatz represents a parameterized quantum circuit composed of alternating layers of a cost layer and a mixing layer. \n",
    "The number of qubits is equal to the number of nodes in the graph. \n",
    "We initialize the state to an even superposition over all basis states. \n",
    "For this example, we use a variational circuit consisting of `p=2` QAOA layers. \n",
    "\n",
    "Below, we use the QAOA utilities from PennyLane to construct the circuit ansatz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import qaoa\n",
    "\n",
    "p = 2  # number of QAOA layers\n",
    "wires = range(num_nodes)  # number of qubits\n",
    "\n",
    "params = np.random.rand(2, p)  # random initial parameters\n",
    "\n",
    "cost_h, mixer_h = qaoa.maxcut(graph)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=len(wires))\n",
    "\n",
    "\n",
    "# Defines a layer of the QAOA ansatz from the cost and mixer Hamiltonians\n",
    "def qaoa_layer(gamma, alpha):\n",
    "    qaoa.cost_layer(gamma, cost_h)\n",
    "    qaoa.mixer_layer(alpha, mixer_h)\n",
    "\n",
    "\n",
    "# Repeatedly applies layers of the QAOA ansatz\n",
    "def circuit(params, **kwargs):\n",
    "    p = params.shape[1]\n",
    "    for w in wires:\n",
    "        qml.Hadamard(wires=w)\n",
    "    qml.layer(qaoa_layer, p, params[0], params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a7f12",
   "metadata": {},
   "source": [
    "We can visualize the circuit with the built-in PennyLane drawing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ce4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "qml.draw_mpl(circuit)(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133e8cf",
   "metadata": {},
   "source": [
    "## Optimization with gradient descent\n",
    "\n",
    "When solving the Max-Cut problem with QAOA, an optimizer updates the parameters in a parametrized circuit to minimize the cost function. While the parameters are updated in every iteration, the parametrized circuit is the same throughout the optimization process. \n",
    "\n",
    "We use the gradient descent optimizer from PennyLane to optimize the variational parameters in the circuit ansatz. \n",
    "Additionally, we print the value of the loss function at each training step using the `log_metric` function from `braket.jobs.metrics`.\n",
    "This will be beneficial later so we can monitor training progress for long-running algorithms from the [Amazon Braket Console](https://console.aws.amazon.com/braket/home). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.jobs.metrics import log_metric\n",
    "\n",
    "\n",
    "def run_qaoa(p=1, steps=10):\n",
    "    graph = nx.read_adjlist(input_file_path, nodetype=int)\n",
    "    list(graph.nodes)\n",
    "\n",
    "    cost_h, _mixer_h = qaoa.maxcut(graph)\n",
    "    params = np.random.rand(2, p)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def cost_function(params):\n",
    "        circuit(params)\n",
    "        return qml.expval(cost_h)\n",
    "\n",
    "    # training loop\n",
    "    optimizer = qml.GradientDescentOptimizer()\n",
    "    for i in range(steps):\n",
    "        params = optimizer.step(cost_function, params)\n",
    "\n",
    "        log_metric(metric_name=\"loss\", value=cost_function(params), iteration_number=i)\n",
    "\n",
    "    np.save(\"optimal_params.npy\", params)\n",
    "\n",
    "    return cost_function(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_qaoa(p=1, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fce6c",
   "metadata": {},
   "source": [
    "Great! The training seems to be working since the cost function is decreasing in every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e40486",
   "metadata": {},
   "source": [
    "## Run as a hybrid job\n",
    "\n",
    "Now let's run the algorithm asynchronously on Amazon Braket. \n",
    "We simply annotate the function with `@hybrid_job` and call it as usual. \n",
    "We also supply the input data set, in this case the graph information. \n",
    "For more information of hybrid jobs see the [documentation](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs.html). \n",
    "\n",
    "Note that creating hybrid jobs with the `@hybrid_job` decorator is only supported on Python 3.10. \n",
    "For other versions, you may submit Python [scripts](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs.html) or specify a [custom container image](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs-byoc.html).\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> When using PennyLane with Braket QPU devices many training algorithms will benefit from enabling parametric compilation. When running hybrid job on a supported QPU, Braket will compile the circuit once, without the need to recompile for subsequent parameter updates to the same circuit, resulting up to 10x faster runtime.  To use parametric circuits with PennyLane, all you need to do is specify the flag: <code>parametrize_differentiable=True</code>\n",
    " when instantiating the Braket device through PennyLane in your algorithm script, and Amazon Braket will handle the rest.\n",
    "    To learn more about parametric circuits, you can read the \n",
    "    <a href=\"https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs-parametric-compilation.html\">Amazon Braket developer guide</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f455",
   "metadata": {},
   "source": [
    "## Saving progress with checkpoints\n",
    "\n",
    "It is best practice to regularly save interim progress of your hybrid job as checkpoints. If your hybrid job terminates unexpectedly, for instance, if a QPU becomes unavailable, you can create a new hybrid job and load its training progress from a checkpoint. \n",
    "\n",
    "The following is a minimal working example for saving and loading checkpoints with a hybrid job decorator:\n",
    "```python\n",
    "from braket.jobs import save_job_checkpoint, load_job_checkpoint, hybrid_job\n",
    "\n",
    "@hybrid_job(device=None, wait_until_complete=True)\n",
    "def function():\n",
    "    save_job_checkpoint({\"a\": 1})\n",
    "\n",
    "job = function()\n",
    "job_name = job.name\n",
    "job_arn = job.arn\n",
    "\n",
    "@hybrid_job(device=None, wait_until_complete=True, copy_checkpoints_from_job=job_arn)\n",
    "def continued_function():\n",
    "    load_job_checkpoint(job_name)\n",
    "\n",
    "continued_job = continued_function()\n",
    "```\n",
    "\n",
    "In the first hybrid job, we call `save_job_checkpoint` with a dictionary containing the data we want to save. \n",
    "By default, every value must be serializable as text. \n",
    "For checkpointing more complex Python objects, such as numpy arrays, you may set \n",
    "`data_format = PersistedJobDataFormat.PICKLED_V4`. \n",
    "This code creates and overwrites a checkpoint file with default name `<jobname>.json` in your hybrid job artifacts under a subfolder called \"checkpoints\". \n",
    "\n",
    "To create a new hybrid job to continue from the checkpoint, we need to pass `copy_checkpoints_from_job=job_arn` where `job_arn` is the hybrid job ARN of the previous job. \n",
    "Then we use `load_job_checkpoint(job_name)` to load from the checkpoint. \n",
    "\n",
    "Now we are ready to turn the entire QAOA training algorithm into a hybrid job. In the following code, we define the hybrid job algorithm, input data, and save a checkpoint each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5052d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.jobs import hybrid_job, save_job_checkpoint\n",
    "from braket.jobs.config import InstanceConfig\n",
    "from braket.jobs_data import PersistedJobDataFormat\n",
    "from braket.tracking import Tracker\n",
    "\n",
    "\n",
    "@hybrid_job(\n",
    "        device=\"local:pennylane/lightning.qubit\", \n",
    "        input_data=input_file_path,\n",
    "        instance_config=InstanceConfig(instanceType=\"ml.m5.xlarge\"))\n",
    "def run_qaoa_hybrid_job_m5(p=1, steps=10):\n",
    "    from pennylane import qaoa\n",
    "    params = np.random.rand(2, p)\n",
    "\n",
    "    braket_task_tracker = Tracker()\n",
    "\n",
    "    graph = nx.read_adjlist(input_file_path, nodetype=int)\n",
    "    wires = list(graph.nodes)\n",
    "    cost_h, _mixer_h = qaoa.maxcut(graph)\n",
    "\n",
    "    dev = qml.device(\"default.qubit\", wires=len(wires))\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def cost_function(params):\n",
    "        circuit(params)\n",
    "        return qml.expval(cost_h)\n",
    "\n",
    "    # training loop\n",
    "    optimizer = qml.GradientDescentOptimizer()\n",
    "    for i in range(steps):\n",
    "        params = optimizer.step(cost_function, params)\n",
    "        cost = float(cost_function(params))\n",
    "\n",
    "        log_metric(metric_name=\"loss\", value=cost, iteration_number=i)\n",
    "\n",
    "        # save checkpoint data\n",
    "        save_job_checkpoint(\n",
    "            checkpoint_data={\n",
    "                \"iteration\": i,\n",
    "                \"params\": params.numpy(),\n",
    "                \"cost\": cost,\n",
    "            },\n",
    "            data_format=PersistedJobDataFormat.PICKLED_V4,\n",
    "        )\n",
    "\n",
    "    # save final results\n",
    "    np.save(\"optimal_params.npy\", params)\n",
    "\n",
    "    return {\n",
    "        \"params\": params.numpy(),\n",
    "        \"cost\": cost,\n",
    "        \"task summary\": braket_task_tracker.quantum_tasks_statistics(),\n",
    "        \"estimated cost\": braket_task_tracker.qpu_tasks_cost()\n",
    "        + braket_task_tracker.simulator_tasks_cost(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5adbf5",
   "metadata": {},
   "source": [
    "To run the hybrid job, we invoke the function as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63740d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = run_qaoa_hybrid_job_m5(p=1, steps=5)\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac58e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import qaoa\n",
    "\n",
    "from braket.aws import AwsSession\n",
    "from braket.jobs import hybrid_job\n",
    "from braket.jobs.config import InstanceConfig\n",
    "from braket.jobs.image_uris import Framework, retrieve_image\n",
    "\n",
    "\n",
    "@hybrid_job(\n",
    "        device=\"local:pennylane/lightning.gpu\",        \n",
    "        input_data=input_file_path,\n",
    "        image_uri=retrieve_image(Framework.PL_PYTORCH, AwsSession().region),\n",
    "        instance_config=InstanceConfig(instanceType=\"ml.g4dn.xlarge\"))\n",
    "def run_qaoa_hybrid_job_g4dn(p=1, steps=10):\n",
    "    import os\n",
    "\n",
    "    params = np.random.rand(2, p)\n",
    "\n",
    "    braket_task_tracker = Tracker()\n",
    "\n",
    "    graph = nx.read_adjlist(input_file_path, nodetype=int)\n",
    "    wires = list(graph.nodes)\n",
    "    cost_h, _mixer_h = qaoa.maxcut(graph)\n",
    "\n",
    "    device_string = os.environ[\"AMZN_BRAKET_DEVICE_ARN\"]\n",
    "    prefix, device_name = device_string.split(\"/\")\n",
    "    dev= qml.device(device_name, wires=len(wires))\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def cost_function(params):\n",
    "        circuit(params)\n",
    "        return qml.expval(cost_h)\n",
    "\n",
    "    # training loop\n",
    "    optimizer = qml.GradientDescentOptimizer()\n",
    "    for i in range(steps):\n",
    "        params = optimizer.step(cost_function, params)\n",
    "        cost = float(cost_function(params))\n",
    "\n",
    "        log_metric(metric_name=\"loss\", value=cost, iteration_number=i)\n",
    "\n",
    "        # save checkpoint data\n",
    "        save_job_checkpoint(\n",
    "            checkpoint_data={\n",
    "                \"iteration\": i,\n",
    "                \"params\": params.numpy(),\n",
    "                \"cost\": cost,\n",
    "            },\n",
    "            data_format=PersistedJobDataFormat.PICKLED_V4,\n",
    "        )\n",
    "\n",
    "    # save final results\n",
    "    np.save(\"optimal_params.npy\", params)\n",
    "\n",
    "    return {\n",
    "        \"params\": params.numpy(),\n",
    "        \"cost\": cost,\n",
    "        \"task summary\": braket_task_tracker.quantum_tasks_statistics(),\n",
    "        \"estimated cost\": braket_task_tracker.qpu_tasks_cost()\n",
    "        + braket_task_tracker.simulator_tasks_cost(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = run_qaoa_hybrid_job_g4dn(p=1, steps=5)\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3a2b9",
   "metadata": {},
   "source": [
    "We see the default name of the hybrid job is the function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff272af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213820c",
   "metadata": {},
   "source": [
    "We also record the hybrid job ARN for resuming with checkpoints in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_job_name = job.name\n",
    "previous_job_arn = job.arn\n",
    "print(previous_job_arn)\n",
    "print(previous_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190654e",
   "metadata": {},
   "source": [
    "We can check if the job has started running with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72041fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c429b",
   "metadata": {},
   "source": [
    "We can monitor the training progress in near-real time on the [Amazon Braket Console](https://console.aws.amazon.com/braket/home) as shown below. \n",
    "\n",
    "![Monitor training progress in the Amazon Braket Console](console_figures/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b84c4",
   "metadata": {},
   "source": [
    "After the job is completed, we can view the result and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(job.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d29fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to wait a bit before metrics show up\n",
    "# If metrics aren't there, try again after 5 seconds\n",
    "import time\n",
    "\n",
    "time.sleep(10)\n",
    "print(job.metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29278499",
   "metadata": {},
   "source": [
    "Now we plot the metrics recorded during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44a240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# A demonstration of plotting the metrics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(job.metrics()).sort_values(\"iteration_number\")\n",
    "\n",
    "ax = plt.figure().gca()\n",
    "figure = df.plot(x=\"iteration_number\", y=\"loss\", ax=ax, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f009ca",
   "metadata": {},
   "source": [
    "## Continuing from a previous hybrid job with checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1cb80",
   "metadata": {},
   "source": [
    "Since we saved a checkpoint in the hybrid job, we can create a new hybrid job to resume by loading the data from that checkpoint.\n",
    "This next hybrid job adds an additional 10 steps to the QAOA training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45535a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.jobs import load_job_checkpoint\n",
    "\n",
    "\n",
    "@hybrid_job(device=None, input_data=input_file_path, copy_checkpoints_from_job=previous_job_arn)\n",
    "def continued_run_qaoa_hybrid_job(p=1, steps=10):\n",
    "    # Resume from last checkpoint\n",
    "    checkpoint = load_job_checkpoint(previous_job_name)\n",
    "\n",
    "    start_iteration = checkpoint[\"iteration\"]\n",
    "    params = checkpoint[\"params\"]\n",
    "\n",
    "    # code below is similar for both hybrid jobs\n",
    "    braket_task_tracker = Tracker()\n",
    "\n",
    "    graph = nx.read_adjlist(input_file_path, nodetype=int)\n",
    "    wires = list(graph.nodes)\n",
    "    cost_h, _mixer_h = qaoa.maxcut(graph)\n",
    "\n",
    "    dev = qml.device(\"default.qubit\", wires=len(wires))\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def cost_function(params):\n",
    "        circuit(params)\n",
    "        return qml.expval(cost_h)\n",
    "\n",
    "    # training loop\n",
    "    optimizer = qml.GradientDescentOptimizer()\n",
    "    for i in range(start_iteration, steps):\n",
    "        params = optimizer.step(cost_function, params)\n",
    "        cost = float(cost_function(params))\n",
    "\n",
    "        log_metric(metric_name=\"loss\", value=cost, iteration_number=i)\n",
    "\n",
    "    # save final results\n",
    "    np.save(\"continued_optimal_params.npy\", params)\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"cost\": cost,\n",
    "        \"task summary\": braket_task_tracker.quantum_tasks_statistics(),\n",
    "        \"estimated cost\": braket_task_tracker.qpu_tasks_cost()\n",
    "        + braket_task_tracker.simulator_tasks_cost(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "continued_job = continued_run_qaoa_hybrid_job(p=1, steps=10)\n",
    "print(continued_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f895ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "continued_result = continued_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb01635",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)  # wait for new metrics to load\n",
    "continued_job.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b35b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(job.metrics())\n",
    "continued_df = pd.DataFrame(continued_job.metrics())\n",
    "df = pd.concat([df, continued_df], ignore_index=True).sort_values(\"iteration_number\")\n",
    "\n",
    "ax = plt.figure().gca()\n",
    "figure = df.plot(x=\"iteration_number\", y=\"loss\", ax=ax, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a95cc1",
   "metadata": {},
   "source": [
    "We see how adding 10 more iterations has improved the convergence significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Estimated cost to run quantum tasks in this notebook: {job.result()['estimated cost'] + continued_job.result()['estimated cost']} USD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d5631",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we set up a Max-Cut problem with a random graph using PennyLane. \n",
    "We saved the graph to a local file and provided it as input data to our hybrid job.\n",
    "Hyperparameters required for the algorithm are passed in as function arguments. \n",
    "The result is retrieved after the QAOA algorithm is completed. \n",
    "Lastly, we demonstrated how to use checkpoints to save and load training progress of a hybrid job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
