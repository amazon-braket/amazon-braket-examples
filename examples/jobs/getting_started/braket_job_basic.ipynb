{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Amazon Braket Hybrid Jobs\n",
    "\n",
    "This tutorial shows how to run a Amazon Braket Hybrid Job on Amazon Braket simulators and quantum devices. \n",
    "To get started, we consider small circuits with only one qubit and one gate in this example notebook.\n",
    "\n",
    "\n",
    "## Learning outcomes \n",
    "* Run our first Braket Job! \n",
    "* Understand how to run scripts or functions\n",
    "* Monitor job status and view logs \n",
    "* Save results from a job\n",
    "* Use Braket Jobs within a specific AWS session\n",
    "* Run Braket Jobs on quantum hardware \n",
    "* Create a Braket Job using the Braket console.\n",
    "* Use Local Braket Jobs to quickly test code [Docker required]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm script\n",
    "\n",
    "To create a Braket Job, we first need a Python script that we want to run. In this example, it's contained in `algorithm_script.py`. The script is printed in the code cell below for convenience. \n",
    "\n",
    "As shown, each of our circuits has only one $X$ rotation gate with a random angle. The circuit is repeated five times with different random rotations. We write the algorithm script as we usually do, except that we do not specify the backend QPUs or simulators explicitly. Instead, it is provided through environment variables which are passed to the algorithm script when creating a Braket Job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This block is a copy of the algorithm script.\n"
     ]
    }
   ],
   "source": [
    "%%script echo \"This block is a copy of the algorithm script.\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from braket.aws import AwsDevice\n",
    "from braket.circuits import Circuit\n",
    "from braket.jobs import save_job_result\n",
    "\n",
    "\n",
    "print(\"Test job started!\")\n",
    "\n",
    "# Use the device declared in the creation script\n",
    "device = AwsDevice(os.environ[\"AMZN_BRAKET_DEVICE_ARN\"])\n",
    "\n",
    "counts_list = []\n",
    "angle_list = []\n",
    "for _ in range(5):\n",
    "    angle = np.pi * np.random.randn()\n",
    "    random_circuit = Circuit().rx(0, angle)\n",
    "\n",
    "    task = device.run(random_circuit, shots=100)\n",
    "    counts = task.result().measurement_counts\n",
    "\n",
    "    angle_list.append(angle)\n",
    "    counts_list.append(counts)\n",
    "    print(counts)\n",
    "\n",
    "# Save the variables of interest so that we can access later\n",
    "save_job_result({\"counts\": counts_list, \"angle\": angle_list})\n",
    "\n",
    "print(\"Test job completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Braket Job \n",
    "\n",
    "In this notebook, we use <code>AwsQuantumJob.create</code> to create a Braket Job. When the Braket Job is created, it starts an EC2 instance and spins up a Docker container. The instance type, container, and other configurations can be specified via keyword arguments. See the [developer guide](https://docs.aws.amazon.com/braket/latest/developerguide/what-is-braket.html) and other example notebooks for more information.\n",
    "\n",
    "The required inputs of <code>AwsQuantumJob</code> are:\n",
    "- <b>device</b>: The arn of the Braket simulator or QPU we want to use. It will be passed as an environment variable to the algorithm script.\n",
    "- <b>source_module</b>: The path to a file or a Python module that contains your algorithm script. It will be uploaded to the container for running the Braket Job.\n",
    "- <b>entry point</b>: The path relative to the source_module. It points to the code to be run when the Braket Job starts. \n",
    "- <b>wait_until_complete (optional)</b>: If true, the function call will wait until the Braket Job is completed and will additionally print logs to the local console. Otherwise, it will run asynchronously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsQuantumJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell should take about 5 mins\n",
    "job = AwsQuantumJob.create(\n",
    "    device=\"arn:aws:braket:::device/quantum-simulator/amazon/sv1\",\n",
    "    source_module=\"algorithm_script.py\",\n",
    "    entry_point=\"algorithm_script\",\n",
    "    wait_until_complete=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the algorithm script is in one file, so we set <code>source_module</code> to be <code>algorithm_script.py</code> and <code>entry_point</code> to be <code>algorithm_script</code>. Depending on your application, there are other options for setting the algorithm script. For example, if you wish to only execute a part of <code>algorithm_script.py</code> at the start of a Braket Job, you can package that part to be a <code>starting_function()</code>. Then the input arguments would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_module = \"algorithm_script.py\"\n",
    "entry_point = \"algorithm_script:starting_function\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your algorithm script requires other files such as helper functions, you can put them all in one folder, say the <code>algorithm_folder</code>. The input arguments would then be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_module = \"algorithm_folder\"\n",
    "entry_point = \"algorithm_folder.algorithm_script:starting_function\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking progress and results\n",
    "\n",
    "The status of a Braket Job can be checked by calling <code>job.state()</code>. Once completed, the result can be retrieved using <code>job.result()</code>. Logs and metadata are also accessible via `job.logs()` and `job.metadata()`. If you lose the job variable, you can always retrieve it by a unique arn which you can find in the Amazon Braket Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = job.result()  # will return once  job.state() = \"COMPLETE\"\n",
    "print(\"counts\")\n",
    "print(results[\"counts\"])\n",
    "print(\"angles\")\n",
    "print(results[\"angles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "print(job.logs())\n",
    "print(job.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.download_result()  # download job result to local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on QPUs\n",
    "\n",
    "Braket Jobs can run our quantum processing units (QPUs) available through Amazon Braket. Be aware that QPU devices are region specific. \n",
    "\n",
    "Running jobs on QPUs has the advantage of priority access to the QPU. Quantum tasks within a single job are grouped together to attempt to run sequentially. This reduces the risk of certain task being delayed or drifting calibrations on the device. \n",
    "\n",
    "We can seamlessly swap our SV1 simulator for a QPU by changing the device argument in `AwsQuantumJob.create()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the AWS region matched the device availability region.\n",
    "# This cell could take a long depending on our position in the queue and device availability\n",
    "job = AwsQuantumJob.create(\n",
    "    device=\"arn:aws:braket:::device/qpu/rigetti/Aspen-9\",\n",
    "    source_module=\"algorithm_script.py\",\n",
    "    entry_point=\"algorithm_script\",\n",
    "    wait_until_complete=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Sessions\n",
    "\n",
    "We can customize where Braket Jobs saves and loads results in Amazon S3 by providing the AWS session information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsSession\n",
    "\n",
    "# Set Amazon S3 bucket\n",
    "aws_session = AwsSession(default_bucket=\"amazon-braket-{region}-{account_id}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Braket Job with this S3 bucket, we pass `aws_session` as an argument to ` AwsQuantumJob.create()`\n",
    "\n",
    "```\n",
    "job = AwsQuantumJob.create(\n",
    "    \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\",\n",
    "    source_module=\"algorithm_script.py\",\n",
    "    entry_point=\"algorithm_script\",\n",
    "    aws_session = aws_session # using specific S3 bucket\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Braket Job from the Brake console\n",
    "Besides creating a Braket Job programmatically using <code>AwsQuantumJob.create</code>, there is also an option to create a job on the Braket console. Follow [this link](https://998640816978-braket.us-west-2.console.aws-dev.amazon.com/braket/home#/job/create) to the \"Create a new job\" page. First, we need to give our new job a unique name. In the advance setting, we can choose the AWS role for this job and the S3 bucket where Braket will put the files associated with this job.\n",
    "<img src=\"console/1-create.png\" alt=\"Create job\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we select the algorithm script for the job. The script can be uploaded from a local console as a single script file. If there are many files, such as helper functions, that go with the algorithm script, we can also upload the files to a S3 bucket and provide the path of the bucket.\n",
    "<img src=\"console/2-algorithm.png\" alt=\"Select algorithm script\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, select a container for our job. The \"Base\" container is enough for the example in this notebook. For information about using other pre-built or custom containers, see the QAOA and BYOC example notebooks for Braket Job.\n",
    "<img src=\"console/3-container.png\" alt=\"Select a container\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the Braket managed simulators or QPU for our job and configure the execution settings. Finally, there are optional settings for hyperparameters, input data, checkpoints and out data. For the usage of these setting, see other example notebooks. After finishing all the settings, we submit the job by clicking the \"create job\" button. We can now view the progress in the Braket console.\n",
    "<img src=\"console/4-execution.png\" alt=\"Configuration for execution\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Braket Jobs\n",
    "\n",
    "Braket Jobs can also be run locally before submitting a job to Amazon Braket. This is recommended for quickly debugging and testing code, but does not provide AWS Console information on the job. This feature requires Docker to be installed on your computer. Amazon Braket Notebook Instances have Docker pre-installed, so you can test local jobs in hosted notebooks instantly. To install Docker in your local environment, follow these [instructions](https://docs.docker.com/get-docker/).\n",
    "\n",
    "To run a job in local mode, simply create a <code>LocalQuantumJob</code> instead of <code>AwsQuantumJob</code>. Local jobs always run synchronously and display the logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.jobs.local.local_job import LocalQuantumJob\n",
    "\n",
    "# This cell should take about 2 min\n",
    "job = LocalQuantumJob.create(\n",
    "    device=\"arn:aws:braket:::device/quantum-simulator/amazon/sv1\",\n",
    "    source_module=\"algorithm_script.py\",\n",
    "    entry_point=\"algorithm_script\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we have created our first Braket Job with a simple batch of five circuits using code and using the Braket console. We learned how to change the Amazon S3 bucket for a job, and how to save results. We learned about running on simulators and QPUs. Lastly, we used local jobs to quickly test code."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a3faae6bbb7a2a59c3b36071b2b18ca9558c49646aca6fb369efee1cbea9b8b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
