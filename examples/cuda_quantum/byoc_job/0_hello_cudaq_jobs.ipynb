{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57cc0f78-56cc-4a24-b5af-7e156a17a002",
   "metadata": {},
   "source": [
    "# Hello CUDA-Q with Braket Hybrid Jobs\n",
    "[CUDA-Q](https://nvidia.github.io/cuda-quantum/latest/index.html) offers a unified programming model designed for hybrid workloads that run on CPUs, GPUs and QPUs. In this notebook, you will learn how to run CUDA-Q programs on Amazon Braket. Specifically, we will be using the Bring Your Own Container (BYOC) feature of Braket Hybrid Jobs. BYOC enables you to configure the environment that you want to use in your jobs. This notebook assumes basic knowledge of Amazon Braket Hybrid Jobs. You can learn about Hybrid Jobs from [this page](https://docs.aws.amazon.com/braket/latest/developerguide/braket-what-is-hybrid-job.html) in the Amazon Braket Developer Guide and the notebooks in [Amazon Braket Examples](https://github.com/amazon-braket/amazon-braket-examples/tree/main/examples/hybrid_jobs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd971e-d6c1-4180-80e3-1844d6c8afc1",
   "metadata": {},
   "source": [
    "The shell script, `container_build_and_push.sh`, in the \"container\" folder will build a Docker container and upload the container image to your [ECR](https://aws.amazon.com/ecr/) repository with the name and region that you specify. You run the script by providing a image name and AWS region where to store the image:\n",
    "```\n",
    "container/container_build_and_push.sh <image-name> <region-name>\n",
    "```\n",
    "The container image will persist in your ECR repository until you update it. The ARN of the image will take the format: `<aws-account-id>.dkr.ecr.<region-name>.amazonaws.com/<container-image-name>:latest`. To learn more about what's under the hood when you call the shell script and how to configure the environment of the job container, you can view the [Appendix](#Appendix:-Container-build-procedure) of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe18f4-0cf1-4d4e-96da-521aac2ab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!container/container_build_and_push.sh amazon-braket-cudaq-job us-west-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2ebf4-24f0-4706-960e-2e3898322cf1",
   "metadata": {},
   "source": [
    "## Running CUDA-Q with Braket\n",
    "Now, we have prepared the environment for CUDA-Q in a container image. Let's run our first CUDA-Q job! First, we start with the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93602c9-c064-452c-85d4-3d2debd38cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braket.jobs import hybrid_job\n",
    "from braket.jobs.config import InstanceConfig\n",
    "from braket.jobs.environment_variables import get_job_device_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa87e5-2b94-4892-ad4e-b59b785ab53b",
   "metadata": {},
   "source": [
    "We also prepare the URI of the container image. Fill the proper value of `aws_account_id`, `region_name` and `container_image_name` in the cell below. For example, with the shell command above, `region_name=\"us-west-2\"` and `container_image_name=\"amazon-braket-cudaq-job\"`. The cell below prints out the image URI. When you use a container image to run a job, it ensures that your code is run in the same environment every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c78b0-5814-4eb2-8604-a13b43c3179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_account_id = \"<aws-account-id>\"\n",
    "region_name = \"<region-name>\"\n",
    "container_image_name = \"<container-image-name>\"\n",
    "\n",
    "image_uri = f\"{aws_account_id}.dkr.ecr.{region_name}.amazonaws.com/{container_image_name}:latest\"\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902c96e-7da5-4ad0-b20b-ef712732e6ec",
   "metadata": {},
   "source": [
    "## Test your CUDA-Q job locally\n",
    "Before submitting a job, it is recommended to test with a local job. A local job runs scripts in a container locally. It is a good way to test your code with a small problem size before scaling up. Note, running a local hybrid job requires Docker installed on the local computer. \n",
    "\n",
    "Here, let's use a Bell circuit with CUDA-Q for the local job. This example does not require a GPU to run. The `hello_quantum` function in the code snippet below defines an experiment to sample a Bell circuit. The string `qpp-cpu` in the `device` keyword argument of the decorator is the name of a CUDA-Q CPU simulator. You can view the tutorial of CUDA-Q and the available backends in the [CUDA-Q documentation](https://nvidia.github.io/cuda-quantum/latest/index.html).\n",
    "\n",
    "When called, the decorated `hello_quantum` function starts a local job because of the keyword `local=True` in the `hybrid_job` decorator. The code inside the `hello_quantum` function will run locally in the environment defined by the container image that you have built earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6bd61-6fb2-4fbc-9d60-93d4161a724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hybrid_job(device=\"local:nvidia/qpp-cpu\", image_uri=image_uri, local=True)\n",
    "def hello_quantum():\n",
    "    import cudaq\n",
    "\n",
    "    # define the backend\n",
    "    device = get_job_device_arn()\n",
    "    cudaq.set_target(device.split(\"/\")[-1])\n",
    "    print(\"CUDA-Q backend: \", cudaq.get_target())\n",
    "\n",
    "    # define the Bell circuit\n",
    "    kernel = cudaq.make_kernel()\n",
    "    qubits = kernel.qalloc(2)\n",
    "    kernel.h(qubits[0])\n",
    "    kernel.cx(qubits[0], qubits[1])\n",
    "\n",
    "    # sample the Bell circuit\n",
    "    result = cudaq.sample(kernel, shots_count=1000)\n",
    "    measurement_probabilities = dict(result.items())\n",
    "    print(\"Samples: \", measurement_probabilities)\n",
    "\n",
    "    return measurement_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c90cb7-baa6-4c51-b828-e1f334b3eb5c",
   "metadata": {},
   "source": [
    "Let's test your CUDA-Q job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402d3b9-1623-4d39-a8e6-f8f69d40ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_quantum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871d290-8173-454a-a69c-d9625b80acc7",
   "metadata": {},
   "source": [
    "## Run your CUDA-Q job\n",
    "After testing locally that your code works correctly in the container environment, you can remove the `local=True` keyword argument (or, equivalently, set `local=False`), so the next job will run on an AWS-managed compute instance. This is great to scale up to larger instances or parallelize your workload over multiple instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329a6f9-8d2e-4067-905a-e16590edfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hybrid_job(device=\"local:nvidia/qpp-cpu\", image_uri=image_uri)\n",
    "def hello_quantum():\n",
    "    import cudaq\n",
    "\n",
    "    device = get_job_device_arn()\n",
    "    cudaq.set_target(device.split(\"/\")[-1])\n",
    "    print(cudaq.get_target())\n",
    "\n",
    "    kernel = cudaq.make_kernel()\n",
    "    qubits = kernel.qalloc(2)\n",
    "    kernel.h(qubits[0])\n",
    "    kernel.cx(qubits[0], qubits[1])\n",
    "\n",
    "    result = cudaq.sample(kernel, shots_count=1000)\n",
    "    measurement_probabilities = dict(result.items())\n",
    "    print(\"Samples: \", measurement_probabilities)\n",
    "\n",
    "    return measurement_probabilities\n",
    "\n",
    "\n",
    "job = hello_quantum()\n",
    "print(job.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d56392-77a9-46cd-8512-bd0ded291b8b",
   "metadata": {},
   "source": [
    "When called, the decorated `hello_quantum` function will create a Braket hybrid job on AWS, running the code defined in the decorated function with the environment specified by the container image built above. You can view the progress of your job with `job.state()` or in the \"Hybrid jobs\" tab of the Amazon Braket Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611f86a-4e23-4aaf-8ab8-df33b7eb050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = job.result()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76eade-78ff-417d-8246-04ccb28b8944",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook shows you how to run your first CUDA-Q program with Amazon Braket Hybrid Jobs. Using the BYOC feature of Amazon Braket and a shell script we provide, you can register a CUDA-Q environment with a few lines of code. Once you have registered your CUDA-Q container image, you can run CUDA-Q programs with Braket Hybrid Jobs and scale your workloads up and out with the range of compute options provided by AWS. In the next tutorials, we will show you how to run CUDA-Q simulations on GPUs ([notebook](1_simulation_with_GPUs.ipynb)) and distribute workloads across multiple instances ([notebook](2_parallel_simulations.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7f189-1036-4585-a641-127d1dbeed88",
   "metadata": {},
   "source": [
    "## Appendix: Procedure of the container build\n",
    "\n",
    "When the shell script, `container_build_and_push.sh`, is called, a Docker container is built with CUDA-Q and other GPU related settings configured. The procedure for BYOC is presented in this page from [Braker Developer Guide](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs-byoc.html). The required files for building a container with CUDA-Q are in the \"container\" folder, including\n",
    "- `Dockerfile`: Describes how the container is built.\n",
    "- `requirements.txt`: Additional Python dependencies to include.\n",
    "- `braket_container.py`: The start-up script of a job container.\n",
    "\n",
    "These files include basic settings to use CUDA-Q in jobs. You can modify these files to suit your needs. For example, you can add more Python dependencies to `requirements.txt` and other dependencies to `Dockerfile`.\n",
    "\n",
    "The shell script `container_build_and_push.sh` automates the procedure of building on top of a Braket managed container and pushing your custom container image. The shell script requires Docker to be installed on your local machine. IF you are using Braket NBI, Docker is already installed. If you don't have Docker in your local environment, you can follow the [instruction in this page](https://www.docker.com/) to install it. The shell script takes two parameters:\n",
    "- image-name\n",
    "- region-name\n",
    "\n",
    "The shell script can be called with the following syntax:\n",
    "```\n",
    "container/container_build_and_push.sh <image-name> <region-name>\n",
    "```\n",
    "By default, the permission policy `AmazonBraketFullAccess` grants access to ECR container images which name start with `amazon-braket`. If you have name the container image differently, you may can modify the perimission of the role you are using. You can view [this page](https://docs.aws.amazon.com/AmazonECR/latest/userguide/repository-policies.html) about permission policy in ECR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
